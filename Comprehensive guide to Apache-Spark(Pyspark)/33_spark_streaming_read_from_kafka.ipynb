{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34889865-2884-4661-bbea-b71d9c28af13",
   "metadata": {},
   "source": [
    "## Spark Streaming read from Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "383273d0-cdd6-4027-b010-eac40bd3f835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-8726940d-0090-4430-bd78-378582f7a886;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.8.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.32 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.2 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.2 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      ":: resolution report :: resolve 425ms :: artifacts dl 21ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.8.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.32 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   12  |   0   |   0   |   0   ||   12  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-8726940d-0090-4430-bd78-378582f7a886\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 12 already retrieved (0kB/6ms)\n",
      "23/01/06 07:23:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://6999a9127218:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Streaming from Kafka</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc70039f610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Streaming from Kafka\") \\\n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \\\n",
    "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0') \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 4) \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419debac-31b7-4fe8-bca2-4b858836e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the streaming_df to read from kafka\n",
    "streaming_df = spark.readStream\\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "    .option(\"subscribe\", \"devices\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6284ebf2-3269-46e9-b361-c0932884ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+---------+------+-----------------------+-------------+\n",
      "|key |value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |topic  |partition|offset|timestamp              |timestampType|\n",
      "+----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+---------+------+-----------------------+-------------+\n",
      "|null|[7B 22 65 76 65 6E 74 49 64 22 3A 20 22 31 34 35 30 33 32 34 61 2D 63 35 34 36 2D 34 31 37 35 2D 61 36 64 38 2D 65 65 35 38 38 32 32 65 31 64 34 31 22 2C 20 22 65 76 65 6E 74 4F 66 66 73 65 74 22 3A 20 31 30 30 33 38 2C 20 22 65 76 65 6E 74 50 75 62 6C 69 73 68 65 72 22 3A 20 22 64 65 76 69 63 65 22 2C 20 22 63 75 73 74 6F 6D 65 72 49 64 22 3A 20 22 43 49 30 30 31 30 31 22 2C 20 22 64 61 74 61 22 3A 20 7B 22 64 65 76 69 63 65 73 22 3A 20 5B 7B 22 64 65 76 69 63 65 49 64 22 3A 20 22 44 30 30 34 22 2C 20 22 74 65 6D 70 65 72 61 74 75 72 65 22 3A 20 32 30 2C 20 22 6D 65 61 73 75 72 65 22 3A 20 22 43 22 2C 20 22 73 74 61 74 75 73 22 3A 20 22 53 55 43 43 45 53 53 22 7D 2C 20 7B 22 64 65 76 69 63 65 49 64 22 3A 20 22 44 30 30 34 22 2C 20 22 74 65 6D 70 65 72 61 74 75 72 65 22 3A 20 31 2C 20 22 6D 65 61 73 75 72 65 22 3A 20 22 43 22 2C 20 22 73 74 61 74 75 73 22 3A 20 22 53 55 43 43 45 53 53 22 7D 2C 20 7B 22 64 65 76 69 63 65 49 64 22 3A 20 22 44 30 30 32 22 2C 20 22 74 65 6D 70 65 72 61 74 75 72 65 22 3A 20 32 31 2C 20 22 6D 65 61 73 75 72 65 22 3A 20 22 43 22 2C 20 22 73 74 61 74 75 73 22 3A 20 22 53 55 43 43 45 53 53 22 7D 5D 7D 2C 20 22 65 76 65 6E 74 54 69 6D 65 22 3A 20 22 32 30 32 33 2D 30 31 2D 30 35 20 31 31 3A 31 33 3A 35 33 2E 36 35 30 33 31 33 22 7D]|devices|0        |0     |2023-01-06 06:05:20.617|0            |\n",
      "+----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+---------+------+-----------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# To the schema of the data,  post a kafka message and change readStream to read \n",
    "# streaming_df.printSchema()\n",
    "# streaming_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20666f8-0ccf-40a5-bc33-1b1b35284687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON Schema\n",
    "from pyspark.sql.types import StringType, StructField, StructType, ArrayType, LongType\n",
    "json_schema = StructType([StructField('customerId', StringType(), True), \\\n",
    "StructField('data', StructType([StructField('devices', ArrayType(StructType([ \\\n",
    "StructField('deviceId', StringType(), True), \\\n",
    "StructField('measure', StringType(), True), \\\n",
    "StructField('status', StringType(), True), \\\n",
    "StructField('temperature', LongType(), True)]), True), True)]), True), \\\n",
    "StructField('eventId', StringType(), True), \\\n",
    "StructField('eventOffset', LongType(), True), \\\n",
    "StructField('eventPublisher', StringType(), True), \\\n",
    "StructField('eventTime', StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b51ba5-b247-4d49-9cd6-ca9753e132d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse value from binay to string\n",
    "json_df = streaming_df.selectExpr(\"cast(value as string) as value\")\n",
    "\n",
    "# Apply Schema to JSON value column and expand the value\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "json_expanded_df = json_df.withColumn(\"value\", from_json(json_df[\"value\"], json_schema)).select(\"value.*\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "896c9902-bf6a-4fee-be80-7b8732382556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------------------------------------------------------------+------------------------------------+-----------+--------------+--------------------------+\n",
      "|customerId|data                                                                     |eventId                             |eventOffset|eventPublisher|eventTime                 |\n",
      "+----------+-------------------------------------------------------------------------+------------------------------------+-----------+--------------+--------------------------+\n",
      "|CI00101   |{[{D004, C, SUCCESS, 20}, {D004, C, SUCCESS, 1}, {D002, C, SUCCESS, 21}]}|1450324a-c546-4175-a6d8-ee58822e1d41|10038      |device        |2023-01-05 11:13:53.650313|\n",
      "+----------+-------------------------------------------------------------------------+------------------------------------+-----------+--------------+--------------------------+\n",
      "\n",
      "root\n",
      " |-- customerId: string (nullable = true)\n",
      " |-- data: struct (nullable = true)\n",
      " |    |-- devices: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- deviceId: string (nullable = true)\n",
      " |    |    |    |-- measure: string (nullable = true)\n",
      " |    |    |    |-- status: string (nullable = true)\n",
      " |    |    |    |-- temperature: long (nullable = true)\n",
      " |-- eventId: string (nullable = true)\n",
      " |-- eventOffset: long (nullable = true)\n",
      " |-- eventPublisher: string (nullable = true)\n",
      " |-- eventTime: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Validate Schema\n",
    "# json_expanded_df.show(10, False)\n",
    "# json_expanded_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f879dd5-62af-42b7-8201-c4c5053e5b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets explode the data as devices contains list/array of device reading\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "exploded_df = json_expanded_df \\\n",
    "    .select(\"customerId\", \"eventId\", \"eventOffset\", \"eventPublisher\", \"eventTime\", \"data\") \\\n",
    "    .withColumn(\"devices\", explode(\"data.devices\")) \\\n",
    "    .drop(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b3f3ec9-1512-4118-9f6b-3dd5443be234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerId: string (nullable = true)\n",
      " |-- eventId: string (nullable = true)\n",
      " |-- eventOffset: long (nullable = true)\n",
      " |-- eventPublisher: string (nullable = true)\n",
      " |-- eventTime: string (nullable = true)\n",
      " |-- devices: struct (nullable = true)\n",
      " |    |-- deviceId: string (nullable = true)\n",
      " |    |-- measure: string (nullable = true)\n",
      " |    |-- status: string (nullable = true)\n",
      " |    |-- temperature: long (nullable = true)\n",
      "\n",
      "+----------+------------------------------------+-----------+--------------+--------------------------+----------------------+\n",
      "|customerId|eventId                             |eventOffset|eventPublisher|eventTime                 |devices               |\n",
      "+----------+------------------------------------+-----------+--------------+--------------------------+----------------------+\n",
      "|CI00101   |1450324a-c546-4175-a6d8-ee58822e1d41|10038      |device        |2023-01-05 11:13:53.650313|{D004, C, SUCCESS, 20}|\n",
      "|CI00101   |1450324a-c546-4175-a6d8-ee58822e1d41|10038      |device        |2023-01-05 11:13:53.650313|{D004, C, SUCCESS, 1} |\n",
      "|CI00101   |1450324a-c546-4175-a6d8-ee58822e1d41|10038      |device        |2023-01-05 11:13:53.650313|{D002, C, SUCCESS, 21}|\n",
      "+----------+------------------------------------+-----------+--------------+--------------------------+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check the schema of the exploded_df,  post a kafka message and change readStream to read \n",
    "# exploded_df.printSchema()\n",
    "# exploded_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027929ff-f5d7-4408-9973-998be7128df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the exploded df\n",
    "flattened_df = exploded_df \\\n",
    "    .selectExpr(\"customerId\", \"eventId\", \"eventOffset\", \"eventPublisher\", \"cast(eventTime as timestamp) as eventTime\", \n",
    "                \"devices.deviceId as deviceId\", \"devices.measure as measure\", \n",
    "                \"devices.status as status\", \"devices.temperature as temperature\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c01a060-afa7-4ee1-b1e8-b3a9515969bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerId: string (nullable = true)\n",
      " |-- eventId: string (nullable = true)\n",
      " |-- eventOffset: long (nullable = true)\n",
      " |-- eventPublisher: string (nullable = true)\n",
      " |-- eventTime: timestamp (nullable = true)\n",
      " |-- deviceId: string (nullable = true)\n",
      " |-- measure: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- temperature: long (nullable = true)\n",
      "\n",
      "+----------+------------------------------------+-----------+--------------+--------------------------+--------+-------+-------+-----------+\n",
      "|customerId|eventId                             |eventOffset|eventPublisher|eventTime                 |deviceId|measure|status |temperature|\n",
      "+----------+------------------------------------+-----------+--------------+--------------------------+--------+-------+-------+-----------+\n",
      "|CI00101   |1450324a-c546-4175-a6d8-ee58822e1d41|10038      |device        |2023-01-05 11:13:53.650313|D004    |C      |SUCCESS|20         |\n",
      "|CI00101   |1450324a-c546-4175-a6d8-ee58822e1d41|10038      |device        |2023-01-05 11:13:53.650313|D004    |C      |SUCCESS|1          |\n",
      "|CI00101   |1450324a-c546-4175-a6d8-ee58822e1d41|10038      |device        |2023-01-05 11:13:53.650313|D002    |C      |SUCCESS|21         |\n",
      "+----------+------------------------------------+-----------+--------------+--------------------------+--------+-------+-------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check the schema of the flattened_df,  post a kafka message and change readStream to read \n",
    "# flattened_df.printSchema()\n",
    "# flattened_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5461f1-a106-4e33-8d16-6c51b8718161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the dataframes to find the average temparature\n",
    "# per Customer per device throughout the day for SUCCESS events\n",
    "from pyspark.sql.functions import to_date, avg\n",
    "\n",
    "agg_df = flattened_df.where(\"STATUS = 'SUCCESS'\") \\\n",
    "    .withColumn(\"eventDate\", to_date(\"eventTime\", \"yyyy-MM-dd\")) \\\n",
    "    .groupBy(\"customerId\",\"deviceId\",\"eventDate\") \\\n",
    "    .agg(avg(\"temperature\").alias(\"avg_temp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3590f85-6881-4271-bef4-915d00a9bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerId: string (nullable = true)\n",
      " |-- deviceId: string (nullable = true)\n",
      " |-- eventDate: date (nullable = true)\n",
      " |-- avg_temp: double (nullable = true)\n",
      "\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "+----------+--------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check the schema of the agg_df, post a kafka message and change readStream to read \n",
    "# agg_df.printSchema()\n",
    "# agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0057dc-9034-4667-89e6-b62b8028c8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/06 07:24:10 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "+----------+--------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "+----------+--------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "+----------+--------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "+----------+--------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 6\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 7\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 8\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 9\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 10\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 11\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 12\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 13\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 14\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 15\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 16\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 17\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 18\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 19\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 20\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 21\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 22\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 23\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00104|    D005|2023-01-06|     4.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00104|    D001|2023-01-06|    23.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 24\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00104|    D005|2023-01-06|     4.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00104|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 25\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00104|    D005|2023-01-06|     4.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00104|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 26\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00104|    D005|2023-01-06|     4.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00104|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 27\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00104|    D005|2023-01-06|     4.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00101|    D003|2023-01-06|    28.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00104|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 28\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00104|    D005|2023-01-06|     4.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00101|    D003|2023-01-06|    28.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00104|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 29\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00104|    D005|2023-01-06|     4.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00101|    D003|2023-01-06|    28.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00104|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 30\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00104|    D005|2023-01-06|     4.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00101|    D003|2023-01-06|    28.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00104|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 31\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00104|    D005|2023-01-06|     4.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00119|    D003|2023-01-06|    17.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00101|    D003|2023-01-06|    28.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00104|    D001|2023-01-06|    23.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 32\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00104|    D005|2023-01-06|     4.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00119|    D003|2023-01-06|    17.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00101|    D003|2023-01-06|    28.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00104|    D001|2023-01-06|    23.0|\n",
      "|   CI00117|    D003|2023-01-06|    13.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 33\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00104|    D005|2023-01-06|     4.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00119|    D003|2023-01-06|    17.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00101|    D003|2023-01-06|    28.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00104|    D001|2023-01-06|    23.0|\n",
      "|   CI00117|    D003|2023-01-06|    13.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 34\n",
      "-------------------------------------------\n",
      "+----------+--------+----------+--------+\n",
      "|customerId|deviceId| eventDate|avg_temp|\n",
      "+----------+--------+----------+--------+\n",
      "|   CI00105|    D002|2023-01-05|    20.0|\n",
      "|   CI00101|    D002|2023-01-05|    21.0|\n",
      "|   CI00112|    D003|2023-01-06|    15.0|\n",
      "|   CI00104|    D005|2023-01-06|     4.0|\n",
      "|   CI00101|    D004|2023-01-05|    10.5|\n",
      "|   CI00114|    null|2023-01-06|     3.0|\n",
      "|   CI00110|    D001|2023-01-06|    14.0|\n",
      "|   CI00119|    D003|2023-01-06|    17.0|\n",
      "|   CI00116|    D005|2023-01-06|     2.0|\n",
      "|   CI00101|    D003|2023-01-06|    28.0|\n",
      "|   CI00118|    D001|2023-01-06|    23.0|\n",
      "|   CI00104|    D001|2023-01-06|    23.0|\n",
      "|   CI00117|    D003|2023-01-06|    13.0|\n",
      "|   CI00106|    null|2023-01-06|    18.0|\n",
      "+----------+--------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/local/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m writing_df \u001b[38;5;241m=\u001b[39m agg_df\u001b[38;5;241m.\u001b[39mwriteStream \\\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsole\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpointLocation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39moutputMode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplete\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Start the streaming application to run until the following happens\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 1. Exception in the running program\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 2. Manual Interruption\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mwriting_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/spark/python/pyspark/sql/streaming.py:107\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Write the output to console sink to check the output\n",
    "writing_df = agg_df.writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"checkpointLocation\",\"checkpoint_dir\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .start()\n",
    "    \n",
    "# Start the streaming application to run until the following happens\n",
    "# 1. Exception in the running program\n",
    "# 2. Manual Interruption\n",
    "writing_df.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d71a4-c35f-4e00-9a48-4e7c76f5bbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
